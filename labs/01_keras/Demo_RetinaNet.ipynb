{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection using RetinaNet\n",
    "\n",
    "RetinaNet is a neural network architecture for object detection described in [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002) by Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He and Piotr Doll√°r.\n",
    "\n",
    "The following shows how to use the [TorchVision implementation](https://pytorch.org/vision/main/models/retinanet.html) with model parameters pretrained on the [COCO object detection dataset](http://cocodataset.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights\n",
    "\n",
    "# Load pretrained weights (COCO dataset)\n",
    "weights = RetinaNet_ResNet50_FPN_V2_Weights.COCO_V1\n",
    "model = retinanet_resnet50_fpn_v2(weights=weights)\n",
    "model.eval()\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Objects (Location and Classes) in Test Images\n",
    "\n",
    "The COCO class labels are provided by the pretrained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get COCO class names from the weights metadata\n",
    "labels_to_names = weights.meta[\"categories\"]\n",
    "print(f\"Number of classes: {len(labels_to_names)}\")\n",
    "print(f\"First 10 classes: {labels_to_names[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Get the preprocessing transforms from the weights\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "\n",
    "def detect_and_visualize(image_path_or_array, score_threshold=0.5):\n",
    "    \"\"\"Detect objects in an image and visualize the results.\"\"\"\n",
    "    # Load image\n",
    "    if isinstance(image_path_or_array, str):\n",
    "        image = Image.open(image_path_or_array).convert(\"RGB\")\n",
    "    elif isinstance(image_path_or_array, np.ndarray):\n",
    "        # Convert BGR (OpenCV) to RGB if needed\n",
    "        if image_path_or_array.shape[2] == 3:\n",
    "            image = Image.fromarray(image_path_or_array[..., ::-1])  # BGR to RGB\n",
    "        else:\n",
    "            image = Image.fromarray(image_path_or_array)\n",
    "    else:\n",
    "        image = image_path_or_array\n",
    "    \n",
    "    # Preprocess\n",
    "    image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "    print(f\"Input shape: {image_tensor.shape}, dtype: {image_tensor.dtype}\")\n",
    "    \n",
    "    # Run inference\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image_tensor)\n",
    "    print(f\"Processing time: {time.time() - start:.2f}s\")\n",
    "    \n",
    "    # Extract predictions\n",
    "    pred = predictions[0]\n",
    "    boxes = pred[\"boxes\"].cpu().numpy()\n",
    "    scores = pred[\"scores\"].cpu().numpy()\n",
    "    labels = pred[\"labels\"].cpu().numpy()\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Define colors for different classes\n",
    "    cmap = plt.cm.get_cmap(\"tab20\")\n",
    "    \n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        if score < score_threshold:\n",
    "            continue\n",
    "            \n",
    "        x1, y1, x2, y2 = box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        \n",
    "        color = cmap(label % 20)\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), width, height,\n",
    "            linewidth=2, edgecolor=color, facecolor=\"none\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        class_name = labels_to_names[label]\n",
    "        caption = f\"{class_name}: {score:.2f}\"\n",
    "        print(caption)\n",
    "        ax.text(\n",
    "            x1, y1 - 5, caption,\n",
    "            fontsize=10, color=\"white\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=color, alpha=0.8)\n",
    "        )\n",
    "    \n",
    "    ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample image\n",
    "detect_and_visualize(\"webcam_shot.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real World Data\n",
    "\n",
    "Let's play with the laptop webcam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def camera_grab(camera_id=0, fallback_filename=\"webcam_shot.jpeg\"):\n",
    "    \"\"\"Capture an image from the webcam.\"\"\"\n",
    "    camera = cv2.VideoCapture(camera_id)\n",
    "    try:\n",
    "        # Take 10 consecutive snapshots to let the camera automatically tune\n",
    "        # itself and hope that the contrast and lighting of the last snapshot\n",
    "        # is good enough.\n",
    "        for i in range(10):\n",
    "            snapshot_ok, image = camera.read()\n",
    "        if not snapshot_ok:\n",
    "            print(\"WARNING: could not access camera, using fallback image\")\n",
    "            if fallback_filename:\n",
    "                image = cv2.imread(fallback_filename)\n",
    "    finally:\n",
    "        camera.release()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = camera_grab(camera_id=0)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_visualize(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
