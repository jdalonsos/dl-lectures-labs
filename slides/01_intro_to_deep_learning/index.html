<!DOCTYPE html>
<html>
  <head>
    <title>Deep Learning Lectures</title>
    <meta charset="utf-8">
    <style>
     .left-column {
       width: 50%;
       float: left;
     }
     .right-column {
       width: 50%;
       float: right;
     }
     .grey { color: #bbbbbb; }
      </style>
    <link rel="stylesheet" type="text/css" href="slides.css">
  </head>
  <body>
      <textarea id="source">
class: center, middle

# Introduction to Deep Learning

Roman Yurchak (roman.yurchak@symerio.com)

Course material by Charles Ollion - Olivier Grisel

.affiliations[
  ![IPP](images/logo_ipp.jpeg)
  ![Inria](images/inria-logo.png)
  ![UPS](images/Logo_Master_Datascience.png)
]

---
# Goal of the class

## Overview

- When and where to use DL
- "How" it works
- Frontiers of DL

--

## Arcanes of DL

- Implement using `Numpy`, and `Keras 3` (with `PyTorch` backend)
- Engineering knowledge for building and training DL

---
# What is Deep Learning

### Good old Neural Networks, with more layers/modules

--

### Non-linear, hierarchical, abstract representations of data

--

### Flexible models with any input/output type and size

--

### Differentiable Functional Programming

---
# Typical ML system

.center[
          <img src="images/image_ml.png" style="width: 670px;" />
]
---
# Typical ML system

.center[
          <img src="images/image_ml_2.png" style="width: 670px;" />
]

---
# Deep Learning system

.center[
          <img src="images/image_dl.png" style="width: 700px;" />
]
---
# Why Deep Learning Now?

- Better algorithms &amp; understanding

- .grey[Computing power (GPUs, TPUs, ...)]

- .grey[Data with labels]

- .grey[Open source tools and models]

---
# Why Deep Learning Now?

- Better algorithms &amp; understanding

- Computing power (GPUs, TPUs, ...)

- .grey[Data with labels]

- .grey[Open source tools and models]

.center[
<img src="images/gpu_tpu.png" style="width: 450px;" /><br/><br/>
<small>_GPU and TPU_</small>
]

---
# Why Deep Learning Now?

- Better algorithms &amp; understanding

- Computing power (GPUs, TPUs, ...)

- Data with labels

- .grey[Open source tools and models]

.center[
<img src="images/ng_data_perf.svg" style="width: 400px;" /><br/><br/>
<small>_Adapted from Andrew Ng_</small>
]

---
# Why Deep Learning Now?

- Better algorithms &amp; understanding

- Computing power (GPUs, TPUs, ...)

- Data with labels

- Open source tools and models

.center[
<img src="images/frameworks.png" style="width: 500px;" /><br/><br/>
]

---
# DL Today: Speech-to-Text

.center[
<img src="images/speech.png" style="width: 780px;" />
]

---
# DL Today: Vision

.center[
<img src="images/vision.png" style="width: 720px;" />
]

---
# DL Today: Vision

.center[
<img src="images/vision2.png" style="width: 720px;" />
]

---
# DL Today: NLP

.center[
<img src="images/nlp.png" style="width: 600px;" />
]

---
# DL Today: NLP


.center[
<img src="images/nlp2.png" style="width: 720px;" />
]

--

Modern conversational AI (ChatGPT, Claude, Gemini) is powered by Large Language Models

---
# DL Today: Vision + NLP

.center[
<img src="images/nlp_vision.png" style="width: 760px;" />
]

---
# DL Today: Image translation

.center[
<img src="images/vision_translation.png" style="width: 700px;" />
]

---
# DL Today: Generative models

### Image Generation: From GANs to Diffusion Models

.center[
<img src="images/nvidia_celeb.jpg" style="width: 300px;" />
<br/><small>GAN-generated faces [Nvidia 2017]</small>
]

--

**Modern diffusion models** (2022+): Stable Diffusion, DALL-E 3, Midjourney
- Higher quality, more controllable, text-to-image generation
- Open source models enable widespread adoption

---
# DL Today: Generative models

### Audio & Video Generation

**Text-to-Speech**: ElevenLabs, OpenAI TTS - near-human quality voice synthesis

--

**Music Generation**: Suno, Udio - full songs from text prompts

--

**Video Generation**: Sora, Runway, Pika
- Text/image to video
- Consistent motion and physics understanding

---
## Large Language Models (LLMs)

### Foundation Models (2020+)
- **GPT-4, Claude, Gemini, Llama 3**: Multi-billion parameter models
- Trained on massive text corpora, then fine-tuned for dialogue

--

### Key Capabilities
- Reasoning, problem-solving, code generation
- Multimodal understanding (text + images)

--

### Scaling Laws
- Performance improves predictably with model size and data

---
# Multimodal Models

### Text + Image Understanding

.center[
<img src="images/dalle.png" style="width: 500px;" />
<br/><small>DALL-E: Text-to-image generation</small>
]

--

**Modern vision-language models**: GPT-4V, Claude, Gemini
- Native image understanding (not just generation)
- Visual question answering, document analysis, diagram interpretation

---
# DL Today: AI Agents

### LLMs + Tools + Planning + Memory

--

**Tool use**: Web browsing, code execution, API calls, file operations

--

**Planning**: Breaking complex tasks into steps (chain-of-thought, ReAct)

--

**Memory**: Maintaining context across interactions

--

### Applications
- Research assistants (literature review, data analysis)
- Customer service automation
- Personal productivity tools

---
# DL Today: Coding Agents

### AI-assisted software development

--

**IDE assistants**: GitHub Copilot, Cursor, Windsurf
- Code completion, chat, refactoring within the editor

--

**Coding agents**: Claude Code, OpenAI Codex, Gemini Code Assist
- Autonomous multi-step task completion

_Impact: Fundamentally changing how software is written and maintained_

---
# DL in Science: Genomics

.center[

<img src="images/deepgenomics.png" style="width: 580px;" />
]

--

.center[
<img src="images/protein_fold.gif" style="width: 320px; margin-top: -30px;" /><br/>
<small>[AlphaFold 2](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology): Solved the 50-year protein folding problem (2020)</small>
]

--

**AlphaFold 3** (2024): Extends to protein-ligand and protein-DNA interactions

---

# DL in Science: Chemistry, Physics

.center[
<img src="images/deep_other.png" style="width: 680px;" />
]

---
# DL in Science: Chemistry, Physics

.center[
<img src="images/Accelerating_Eulerian_Fluid_Simulation_with_Convolutional_Networks.gif" style="width: 350px;" />
]

- Finite element simulator accelerated (~100 fold) by a 3D convolutional network

---
# DL for AI in games

.center[
<img src="images/games.png" style="width: 650px;" />
]

--

<small> AlphaGo/Zero: Monte Carlo Tree Search, Deep Reinforcement Learning, self-play </small>

--

<small> Also: OpenAI Five (Dota 2), AlphaStar (StarCraft II) - complex real-time strategy </small>

---
# Outline of the class

### 1. Backpropagation

### 3. Recommender Systems

### 2. Computer Vision (2)

### 4. Classical nlp

### 5. Deep NLP


---

# How this unit works

### Lectures 1h-1h30

### Coding sessions 2h-2h30

- BYO laptop, work in pairs

--

### Machine learning project

- ML project in pairs

--

### Project presentation

---
# Recommended reading

- [deeplearningbook.org](http://www.deeplearningbook.org/): Math and main concepts

- [Francois Chollet's book](https://www.manning.com/books/deep-learning-with-python): Keras programming

- [Aurélien Géron's book](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/):
  Generic Machine Learning with Scikit-learn and Deep Learning with TF/Keras

---
class: center,middle
# Frameworks and Computation Graphs

---
# Libraries & Frameworks

.center[
<img src="images/frameworks.png" style="width: 600px;" /><br/><br/>
]

 Automatic differentiation: _Theano_, TensorFlow, MXnet, CNTK

--

 Dynamic and high level: **TensorFlow 2**, **PyTorch**, Chainer, MinPy, DyNet...

--

**Keras 3**: high level API with multiple backends (**PyTorch**, TensorFlow, JAX)

---
# Computation Graph

.center[
<img src="images/computation_graph_simple_f.png" style="width: 600px;" /><br/><br/>
]

Neural network = parametrized, non-linear function

---
# Computation Graph

.center[
<img src="images/computation_graph_simple.png" style="width: 600px;" /><br/><br/>
]

Computation graph: Directed graph of functions, depending on parameters (neuron weights)
---
# Computation Graph

.center[
<img src="images/computation_graph_simple_expl.png" style="width: 600px;" /><br/><br/>
]

Combination of linear (parametrized) and non-linear functions
---
# Computation Graph

.center[
<img src="images/computation_graph_complicated.png" style="width: 600px;" /><br/><br/>
]

Not only sequential application of functions
---
# Computation Graph

.center[
<img src="images/computation_graph_backprop.png" style="width: 600px;" /><br/><br/>
]

Automatic computation of gradients: all modules are **differentiable**!

--

*Theano* (deprecated), **Tensorflow 1**, etc. build a static computation graph via static declarations.

--

**Tensorflow 2**, **PyTorch**, etc. rely on dynamic differentiable modules: "define-by-run".

--

Vector computation on **CPU** and accelerators (**GPU** and **TPU**).

---
# Computation Graph

.center[
<img src="images/computation_graph_backprop.png" style="width: 600px;" /><br/><br/>
]

Simple keras implementation

```py
model = Sequential()
model.add(Dense(H, input_dim=N))  # defines W0
model.add(Activation("tanh"))
model.add(Dense(K))               # defines W1
model.add(Activation("softmax"))
```

---
class: middle, center

# Lab 1: here in 15min!

    </textarea>
    <style TYPE="text/css">
      code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
    </style>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry
      }
      });
      MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i = 0; i < all.length; i += 1) {
		     all[i].SourceElement().parentNode.className += ' has-jax';
		     }
		     });
		     </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../remark.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create({
        highlightStyle: 'github',
        highlightSpans: true,
        highlightLines: true
      });
    </script>
  </body>
</html>
